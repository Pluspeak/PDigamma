---
title: "Introduction to PDigamma: Heavy-Tailed Count Regression"
author: "Yunfeng Zhang and Shengwang Meng"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
    fig_width: 7
    fig_height: 5
vignette: >
  %\VignetteIndexEntry{Introduction to PDigamma}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE,
  cache = TRUE,
  cache.lazy = FALSE
)
# Fast settings for vignette compilation
B_vignette <- 10
n_vignette <- 30
max_iter_vignette <- 8
```

## Overview

The `PDigamma` package implements the Power-Denominator Digamma family for regression modeling of heavy-tailed count data. This vignette demonstrates:

1. Basic usage with homogeneous and heterogeneous models
2. Comparison with classical approaches (Poisson, Negative Binomial)
3. Tail index interpretation and visualization
4. Handling extreme heavy tails (Sibuya regime)
5. Model selection and bootstrap inference

## Installation and Setup

```{r setup}
library(PDigamma)
library(ggplot2)
library(gridExtra)
set.seed(42)
```

## Example 1: Homogeneous Heavy Tails

First, we simulate data from a PDigamma distribution with fixed parameters:

```{r sim-homogeneous}
# Simulate data: delta = 2.5 (finite variance, heavy tail)
n <- n_vignette
true_params <- list(alpha = 2, delta = 2.5, rho = 1)

y <- rPDigamma(n, true_params$alpha, true_params$delta, true_params$rho)

data_homo <- data.frame(
  y = y,
  x1 = rep(0, n),
  z1 = rep(0, n),
  w1 = rep(0, n)
)

# Summary statistics
cat("Mean:", round(mean(y), 2), "\n")
cat("Variance:", round(var(y), 2), "\n")
cat("Dispersion index (var/mean):", round(var(y)/mean(y), 2), "\n")
cat("Max value:", max(y), "\n")
```

Fit the model with intercept-only formulas:

```{r fit-homogeneous}
# One-line analysis
fit_homo <- pdigamma_analysis(
  formula_alpha = ~ 1,
  formula_delta = ~ 1,
  formula_rho = ~ 1,
  data = data_homo,
  y_var = "y",
  B = B_vignette,  # Reduced for vignette speed
  max_iter = max_iter_vignette,
  verbose = FALSE
)

print(fit_homo)
```

Compare estimated vs true parameters:

```{r compare-homogeneous}
cat("\nTrue vs Estimated:\n")
cat("True delta:", true_params$delta, 
    "| Estimated:", round(mean(fitted(fit_homo, "delta")), 3), "\n")
cat("True alpha:", true_params$alpha,
    "| Estimated:", round(mean(fitted(fit_homo, "alpha")), 3), "\n")
```

## Example 2: Heterogeneous Tail Index

Now we demonstrate the key feature: covariate-dependent tail heaviness.

```{r sim-heterogeneous}
n <- n_vignette

# Covariate affecting tail index
z1 <- rnorm(n, mean = 0, sd = 1)

# True model: log(delta - 1) = 0.5 + 0.3 * z1
# So delta ranges from ~1.8 (heavy tail) to ~3.5 (lighter tail)
xi_true <- c(0.5, 0.3)
delta_true <- 1 + exp(xi_true[1] + xi_true[2] * z1)

# Generate response
y_hetero <- numeric(n)
for (i in 1:n) {
  y_hetero[i] <- rPDigamma(1, alpha = 2, delta = delta_true[i], rho = 1)
}

data_hetero <- data.frame(
  y = y_hetero,
  z1 = z1,
  delta_true = delta_true
)

# Visualize tail heterogeneity
ggplot(data_hetero, aes(x = z1, y = y)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  labs(title = "Response vs Tail Covariate",
       subtitle = "Higher z1 → lighter tails → lower variance",
       x = "Covariate z1 (affects tail index)",
       y = "Count response y") +
  theme_minimal()
```

Fit model with heterogeneous delta:

```{r fit-heterogeneous}
fit_hetero <- pdigamma_analysis(
  formula_alpha = ~ 1,      # Common alpha
  formula_delta = ~ z1,      # Tail index varies with z1
  formula_rho = ~ 1,        # Common rho
  data = data_hetero,
  y_var = "y",
  B = B_vignette,
  max_iter = max_iter_vignette,
  verbose = FALSE
)

summary(fit_hetero)
```

Visualize estimated vs true tail indices:

```{r viz-heterogeneous}
comparison_df <- data.frame(
  z1 = data_hetero$z1,
  delta_true = data_hetero$delta_true,
  delta_estimated = fitted(fit_hetero, "delta")
)

p1 <- ggplot(comparison_df, aes(x = z1)) +
  geom_line(aes(y = delta_true, color = "True"), linewidth = 1) +
  geom_point(aes(y = delta_estimated, color = "Estimated"), alpha = 0.3) +
  geom_smooth(aes(y = delta_estimated, color = "Estimated"), 
              method = "loess", se = FALSE) +
  geom_hline(yintercept = 2, linetype = "dashed", color = "gray50") +
  annotate("text", x = -2, y = 2.1, label = "infinite variance boundary", 
           color = "gray50", size = 3) +
  scale_color_manual(values = c("True" = "black", "Estimated" = "blue")) +
  labs(title = "Tail Index: True vs Estimated",
       y = expression(delta), color = "") +
  theme_minimal() +
  theme(legend.position = "bottom")

p2 <- ggplot(comparison_df, aes(x = delta_true, y = delta_estimated)) +
  geom_point(alpha = 0.3) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "True vs Estimated Delta",
       x = expression(delta[true]), y = expression(delta[estimated])) +
  theme_minimal()

grid.arrange(p1, p2, ncol = 2)
```

## Example 3: Comparison with Classical Models

Compare PDigamma with Poisson and Negative Binomial on heavy-tailed data:

```{r comparison}
# Generate challenging data: mixture of heavy and light tails
n <- n_vignette
group <- sample(1:2, n, replace = TRUE, prob = c(0.7, 0.3))

delta_group <- c(1.8, 3.0)[group]  # Group 1: very heavy tail, Group 2: moderate
y_mix <- numeric(n)
for (i in 1:n) {
  y_mix[i] <- rPDigamma(1, alpha = 1.5, delta = delta_group[i], rho = 0.8)
}

data_mix <- data.frame(
  y = y_mix,
  group = factor(group, labels = c("HighRisk", "LowRisk")),
  x1 = rep(0, n)
)

# Summary by group
aggregate(y ~ group, data = data_mix, 
          FUN = function(x) c(mean = mean(x), var = var(x), max = max(x)))
```

Fit all three models:

```{r fit-comparison}
library(MASS)

# Poisson (will fail badly)
pois_fit <- glm(y ~ 1, data = data_mix, family = poisson)
pois_loglik <- logLik(pois_fit)

# Negative Binomial
nb_fit <- glm.nb(y ~ 1, data = data_mix)
nb_loglik <- logLik(nb_fit)

# PDigamma
pd_fit <- pdigamma_analysis(
  ~ 1, ~ 1, ~ 1,
  data = data_mix, y_var = "y",
  B = B_vignette, 
  max_iter = max_iter_vignette, 
  verbose = FALSE
)

# Compare log-likelihoods
comparison <- data.frame(
  Model = c("Poisson", "Negative Binomial", "PDigamma"),
  LogLikelihood = c(as.numeric(pois_loglik), 
                    as.numeric(nb_loglik), 
                    pd_fit$fit_final$loglik),
  Parameters = c(1, 2, 3),
  AIC = c(-2*as.numeric(pois_loglik) + 2*1,
          -2*as.numeric(nb_loglik) + 2*2,
          -2*pd_fit$fit_final$loglik + 2*3)
)

print(comparison)
```

Visualize tail fit:

```{r viz-comparison}
# Empirical survival function vs fitted
y_unique <- sort(unique(data_mix$y))
emp_surv <- sapply(y_unique, function(x) mean(data_mix$y > x))

# Fitted survival from PDigamma
pd_surv <- survival_PDigamma(y_unique, 
                             alpha = mean(fitted(pd_fit, "alpha")),
                             delta = mean(fitted(pd_fit, "delta")),
                             rho = mean(fitted(pd_fit, "rho")))

# NB survival (continuous approximation)
nb_mean <- mean(fitted(nb_fit))
nb_size <- nb_fit$theta
nb_surv <- 1 - pnbinom(y_unique, size = nb_size, mu = nb_mean)

comparison_surv <- data.frame(
  x = rep(y_unique, 3),
  survival = c(emp_surv, pd_surv, nb_surv),
  type = rep(c("Empirical", "PDigamma", "Negative Binomial"), each = length(y_unique))
)

ggplot(comparison_surv, aes(x = x, y = survival, color = type)) +
  geom_line(linewidth = 1) +
  scale_y_log10() +
  coord_cartesian(xlim = c(0, 100)) +
  labs(title = "Survival Function Comparison (log scale)",
       subtitle = "PDigamma captures heavy tail; NB underestimates extremes",
       x = "y", y = "P(Y > y) [log scale]", color = "") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## Example 4: Model Selection (Boundary LRT)

Demonstrate automatic selection between full model and Generalized Zeta submodel:

```{r model-selection}
# Generate data where rho ≈ 0 (Generalized Zeta is true model)
n <- n_vignette
y_zeta <- rPDigamma(n, alpha = 1.5, delta = 2.2, rho = 0.01)  # Near Zeta boundary

data_zeta <- data.frame(y = y_zeta, x1 = rep(0, n), z1 = rnorm(n))

# Fit with model selection
fit_selected <- pdigamma_analysis(
  ~ 1, ~ z1, ~ 1,
  data = data_zeta, y_var = "y",
  verbose = TRUE,
  B = B_vignette,
  max_iter = max_iter_vignette
)

cat("\nSelected model:", fit_selected$final_model, "\n")
if (!is.null(fit_selected$stage3$lrt_results)) {
  cat("LRT p-value:", round(fit_selected$stage3$lrt_results$p_value, 4), "\n")
}
```

## Example 5: Sibuya Zone and Remedy Protocol

Demonstrate handling of extreme heavy tails (delta ≈ 1.2):

```{r sibuya, eval = FALSE}
# WARNING: This example generates data with infinite variance
# It activates the Sibuya remedy protocol

n <- n_vignette
y_extreme <- rPDigamma(n, alpha = 0.5, delta = 1.15, rho = 0.5)

data_extreme <- data.frame(
  y = y_extreme,
  z1 = rnorm(n)  # Covariate for stratification
)

fit_extreme <- pdigamma_analysis(
  ~ 1, ~ z1, ~ 1,
  data = data_extreme, y_var = "y",
  max_iter = max_iter_vignette,
  verbose = TRUE
)

# Check if remedy was activated
if (fit_extreme$stage4$method == "sibuya_remedy") {
  cat("Sibuya remedy was activated\n")
  print(fit_extreme$stage4$evi_regression)
}
```

## Interpreting Results

### Tail Index (δ) Interpretation

| δ Range   | Variance      | Interpretation                  | Risk Measure                          |
| :-------- | :------------ | :------------------------------ | :------------------------------------ |
| 1.0 - 1.5 | Infinite mean | Extreme Sibuya zone             | EVI regression only                   |
| 1.5 - 2.0 | Infinite      | Very heavy tails (catastrophes) | Wang transform + m-out-of-n bootstrap |
| 2.0 - 3.0 | Finite        | Heavy tails (insurance claims)  | TVaR + standard bootstrap             |
| 3.0+      | Finite        | Moderate tails                  | TVaR + Wald intervals                 |

### Parameter Relationships

```{r parameter-relationships}
# From a fitted model with heterogeneous delta
delta_vals <- seq(1.1, 5, by = 0.1)

# Show relationship between delta and effective tail behavior
tail_behavior <- data.frame(
  delta = delta_vals,
  xi = 1 / (delta_vals - 1),  # Extreme value index
  variance_exists = delta_vals > 2,
  tvar_valid = delta_vals > 2
)

head(tail_behavior, 10)
```

## Advanced Usage: Step-by-Step Control

For custom analysis, run stages separately:

```{r step-by-step}
# Stage 0: Diagnosis
diag <- pre_diagnosis(data_hetero$y, 
                      matrix(1, n, 1), 
                      cbind(1, data_hetero$z1), 
                      matrix(1, n, 1))

# Stage 1: Initialization
init <- initialize_params(data_hetero$y,
                          matrix(1, n, 1),
                          cbind(1, data_hetero$z1),
                          matrix(1, n, 1),
                          model_type = diag$model_type)

# Stage 2: EM fitting
fit_em_result <- fit_em(data_hetero$y,
                       matrix(1, n, 1),
                       cbind(1, data_hetero$z1),
                       matrix(1, n, 1),
                       init,
                       model_type = "A",
                       verbose = FALSE)

# Stage 3: Model selection (if needed)
selected <- model_selection(data_hetero$y,
                            matrix(1, n, 1),
                            cbind(1, data_hetero$z1),
                            matrix(1, n, 1),
                            fit_em_result,
                            model_type = "A",
                            verbose = FALSE)

cat("Manual pipeline complete. Final model:", selected$final_model, "\n")
```

## References

- Sibuya, M. (1979). Generalized hypergeometric, digamma and trigamma distributions. *Annals of the Institute of Statistical Mathematics*, 31(1), 373-390.
- Self, S. G., & Liang, K. Y. (1987). Asymptotic properties of maximum likelihood estimators and likelihood ratio tests under nonstandard conditions. *Journal of the American Statistical Association*, 82(398), 605-610.
- Hill, B. M. (1975). A simple general approach to inference about the tail of a distribution. *The Annals of Statistics*, 3(5), 1163-1174.